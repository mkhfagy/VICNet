{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VICNetV0.02.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkhfagy/VICNet/blob/master/VICNetV0_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hsPdnkzFZTzQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# VICNet by muahann@gmail.com\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QFbz3xYtDVpn",
        "colab_type": "code",
        "outputId": "6e60152d-f742-4bdc-8e55-0772ee53c639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import math\n",
        "import argparse\n",
        "import numpy as np\n",
        "import cntk as C\n",
        "import _cntk_py\n",
        "\n",
        "from cntk.logging import *\n",
        "from cntk.train.training_session import *\n",
        "from cntk import *\n",
        "from cntk.train.distributed import *\n",
        "from cntk.io import ImageDeserializer, MinibatchSource, StreamDef, StreamDefs, FULL_DATA_SWEEP\n",
        "import cntk.io.transforms as xforms\n",
        "from cntk.layers import Convolution2D, Activation, MaxPooling, Dense, Dropout, default_options, Sequential\n",
        "from cntk.initializer import normal\n",
        "\n",
        "# default Paths relative to current python file.\n",
        "abs_path   = os.path.dirname(os.path.abspath(__file__))\n",
        "model_path = os.path.join(abs_path, \"Models\")\n",
        "log_dir = None\n",
        "\n",
        "# model dimensions\n",
        "image_height = 227\n",
        "image_width  = 227\n",
        "num_channels = 3  # RGB\n",
        "num_classes  = 1000\n",
        "model_name   = \"VICNet.model\"\n",
        "\n",
        "# Create a minibatch source.\n",
        "def create_image_mb_source(map_file, is_training, total_number_of_samples):\n",
        "    if not os.path.exists(map_file):\n",
        "        raise RuntimeError(\"File '%s' does not exist.\" %map_file)\n",
        "\n",
        "    # transformation pipeline for the features has jitter/crop only when training\n",
        "    transforms = []\n",
        "    if is_training:\n",
        "        transforms += [\n",
        "            xforms.crop(crop_type='randomside', side_ratio=0.88671875, jitter_type='uniratio') # train uses jitter\n",
        "        ]\n",
        "    else:\n",
        "        transforms += [\n",
        "            xforms.crop(crop_type='center', side_ratio=0.88671875) # test has no jitter\n",
        "        ]\n",
        "\n",
        "    transforms += [\n",
        "        xforms.scale(width=image_width, height=image_height, channels=num_channels, interpolations='linear'),\n",
        "    ]\n",
        "\n",
        "    # deserializer\n",
        "    return MinibatchSource(\n",
        "        ImageDeserializer(map_file, StreamDefs(\n",
        "            features=StreamDef(field='image', transforms=transforms), # first column in map file is referred to as 'image'\n",
        "            labels=StreamDef(field='label', shape=num_classes))),   # and second as 'label'\n",
        "        randomize=is_training,\n",
        "        max_samples=total_number_of_samples,\n",
        "        multithreaded_deserializer=True)\n",
        "\n",
        "# Local Response Normalization layer. See Section 3.3 of the paper:\n",
        "# https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
        "# The mathematical equation is:\n",
        "#   b_{x,y}^i=a_{x,y}^i/(k+\\alpha\\sum_{j=max(0,i-n)}^{min(N-1, i+n)}(a_{x,y}^j)^2)^\\beta\n",
        "# where a_{x,y}^i is the activity of a neuron comoputed by applying kernel i at position (x,y)\n",
        "# N is the total number of kernals, n is half normalization width.\n",
        "def LocalResponseNormalization(k, n, alpha, beta, name=''):\n",
        "    x = C.placeholder(name='lrn_arg')\n",
        "    x2 = C.square(x)\n",
        "    # reshape to insert a fake singleton reduction dimension after the 3th axis (channel axis). Note Python axis order and BrainScript are reversed.\n",
        "    x2s = C.reshape(x2, (1, C.InferredDimension), 0, 1)\n",
        "    W = C.constant(alpha/(2*n+1), (1,2*n+1,1,1), name='W')\n",
        "    # 3D convolution with a filter that has a non 1-size only in the 3rd axis, and does not reduce since the reduction dimension is fake and 1\n",
        "    y = C.convolution (W, x2s)\n",
        "    # reshape back to remove the fake singleton reduction dimension\n",
        "    b = C.reshape(y, C.InferredDimension, 0, 2)\n",
        "    den = C.exp(beta * C.log(k + b))\n",
        "    apply_x = C.element_divide(x, den)\n",
        "    return apply_x\n",
        "\n",
        "# Create the network.\n",
        "def create_alexnet():\n",
        "\n",
        "    # Input variables denoting the features and label data\n",
        "    feature_var = C.input_variable((num_channels, image_height, image_width))\n",
        "    label_var = C.input_variable((num_classes))\n",
        "\n",
        "    # apply model to input\n",
        "    # remove mean value \n",
        "    mean_removed_features = minus(feature_var, constant(114), name='mean_removed_input')\n",
        "    \n",
        "    with default_options(activation=None, pad=True, bias=True):\n",
        "        z = Sequential([\n",
        "            # we separate Convolution and ReLU to name the output for feature extraction (usually before ReLU) \n",
        "            Convolution2D((11,11), 96, init=normal(0.01), pad=False, strides=(4,4), name='conv1'),\n",
        "            Activation(activation=relu, name='relu1'),\n",
        "            LocalResponseNormalization(1.0, 2, 0.0001, 0.75, name='norm1'),\n",
        "            MaxPooling((3,3), (2,2), name='pool1'),\n",
        "\n",
        "            Convolution2D((5,5), 192, init=normal(0.01), init_bias=0.1, name='conv2'), \n",
        "            Activation(activation=relu, name='relu2'),\n",
        "            LocalResponseNormalization(1.0, 2, 0.0001, 0.75, name='norm2'),\n",
        "            MaxPooling((3,3), (2,2), name='pool2'),\n",
        "\n",
        "            Convolution2D((3,3), 384, init=normal(0.01), name='conv3'), \n",
        "            Activation(activation=relu, name='relu3'),\n",
        "            Convolution2D((3,3), 384, init=normal(0.01), init_bias=0.1, name='conv4'), \n",
        "            Activation(activation=relu, name='relu4'),\n",
        "            Convolution2D((3,3), 256, init=normal(0.01), init_bias=0.1, name='conv5'), \n",
        "            Activation(activation=relu, name='relu5'), \n",
        "            MaxPooling((3,3), (2,2), name='pool5'), \n",
        "\n",
        "            Dense(4096, init=normal(0.005), init_bias=0.1, name='fc6'),\n",
        "            Activation(activation=relu, name='relu6'),\n",
        "            Dropout(0.5, name='drop6'),\n",
        "            Dense(4096, init=normal(0.005), init_bias=0.1, name='fc7'),\n",
        "            Activation(activation=relu, name='relu7'),\n",
        "            Dropout(0.5, name='drop7'),\n",
        "            Dense(num_classes, init=normal(0.01), name='fc8')\n",
        "            ])(mean_removed_features)\n",
        "\n",
        "    # loss and metric\n",
        "    ce  = cross_entropy_with_softmax(z, label_var)\n",
        "    pe  = classification_error(z, label_var)\n",
        "    pe5 = classification_error(z, label_var, topN=5)\n",
        "\n",
        "    log_number_of_parameters(z) ; print()\n",
        "\n",
        "    return {\n",
        "        'feature': feature_var,\n",
        "        'label': label_var,\n",
        "        'ce' : ce,\n",
        "        'pe' : pe,\n",
        "        'pe5': pe5,\n",
        "        'output': z\n",
        "    }\n",
        "\n",
        "# Create trainer\n",
        "def create_trainer(network, epoch_size, num_quantization_bits, printer, block_size, warm_up, minibatch_size):\n",
        "    # Set learning parameters\n",
        "    lr_per_mb         = [0.01]*25 + [0.001]*25 + [0.0001]*25 + [0.00001]*25 + [0.000001]\n",
        "    lr_schedule       = C.learning_parameter_schedule(lr_per_mb, minibatch_size=minibatch_size, epoch_size=epoch_size)\n",
        "    mm_schedule       = C.learners.momentum_schedule(0.9, minibatch_size=minibatch_size)\n",
        "    l2_reg_weight     = 0.0005 # CNTK L2 regularization is per sample, thus same as Caffe\n",
        "\n",
        "    if block_size != None and num_quantization_bits != 32:\n",
        "        raise RuntimeError(\"Block momentum cannot be used with quantization, please remove quantized_bits option.\")\n",
        "\n",
        "    # Create learner\n",
        "    local_learner = C.learners.momentum_sgd(network['output'].parameters, lr_schedule, mm_schedule, minibatch_size=minibatch_size, unit_gain=False, l2_regularization_weight=l2_reg_weight)\n",
        "    # Since we reuse parameter settings (learning rate, momentum) from Caffe, we set unit_gain to False to ensure consistency\n",
        "\n",
        "    # Create trainer\n",
        "    if block_size != None:\n",
        "        parameter_learner = block_momentum_distributed_learner(local_learner, block_size=block_size)\n",
        "    else:\n",
        "        parameter_learner = data_parallel_distributed_learner(local_learner, num_quantization_bits=num_quantization_bits, distributed_after=warm_up)\n",
        "\n",
        "    return C.Trainer(network['output'], (network['ce'], network['pe']), parameter_learner, printer)\n",
        "\n",
        "# Train and test\n",
        "def train_and_test(network, trainer, train_source, test_source, minibatch_size, epoch_size, restore):\n",
        "\n",
        "    # define mapping from intput streams to network inputs\n",
        "    input_map = {\n",
        "        network['feature']: train_source.streams.features,\n",
        "        network['label']: train_source.streams.labels\n",
        "    }\n",
        "\n",
        "    # Train all minibatches \n",
        "    training_session(\n",
        "        trainer=trainer, mb_source = train_source,\n",
        "        model_inputs_to_streams = input_map,\n",
        "        mb_size = minibatch_size,\n",
        "        progress_frequency=epoch_size,\n",
        "        checkpoint_config = CheckpointConfig(filename=os.path.join(model_path, model_name), restore=restore),\n",
        "        test_config= TestConfig(test_source, minibatch_size=minibatch_size)\n",
        "    ).train()\n",
        "\n",
        "# Train and evaluate the network.\n",
        "def alexnet_train_and_eval(train_data, test_data, num_quantization_bits=32, block_size=3200, warm_up=0, minibatch_size=256, epoch_size = 1281167, max_epochs=112,\n",
        "                           restore=True, log_to_file=None, num_mbs_per_log=None, gen_heartbeat=True):\n",
        "    _cntk_py.set_computation_network_trace_level(0)\n",
        "\n",
        "    progress_printer = ProgressPrinter(\n",
        "        freq=num_mbs_per_log,\n",
        "        tag='Training',\n",
        "        log_to_file=log_to_file,\n",
        "        rank=Communicator.rank(),\n",
        "        gen_heartbeat=gen_heartbeat,\n",
        "        num_epochs=max_epochs)\n",
        "\n",
        "    network = create_alexnet()\n",
        "    trainer = create_trainer(network, epoch_size, num_quantization_bits, progress_printer, block_size, warm_up, minibatch_size=minibatch_size)\n",
        "    train_source = create_image_mb_source(train_data, True, total_number_of_samples=max_epochs * epoch_size)\n",
        "    test_source = create_image_mb_source(test_data, False, total_number_of_samples=FULL_DATA_SWEEP)\n",
        "    train_and_test(network, trainer, train_source, test_source, minibatch_size, epoch_size, restore)\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    data_path  = os.path.join(abs_path, \"..\", \"..\", \"..\", \"DataSets\", \"ImageNet\")\n",
        "\n",
        "    parser.add_argument('-datadir', '--datadir', help='Data directory where the ImageNet dataset is located', required=False, default=data_path)\n",
        "    parser.add_argument('-outputdir', '--outputdir', help='Output directory for checkpoints and models', required=False, default=None)\n",
        "    parser.add_argument('-logdir', '--logdir', help='Log file', required=False, default=None)\n",
        "    parser.add_argument('-n', '--num_epochs', help='Total number of epochs to train', type=int, required=False, default='112')\n",
        "    parser.add_argument('-m', '--minibatch_size', help='Minibatch size', type=int, required=False, default='256')\n",
        "    parser.add_argument('-e', '--epoch_size', help='Epoch size', type=int, required=False, default='1281167')\n",
        "    parser.add_argument('-q', '--quantized_bits', help='Number of quantized bits used for gradient aggregation', type=int, required=False, default='32')\n",
        "    parser.add_argument('-r', '--restart', help='Indicating whether to restart from scratch (instead of restart from checkpoint file by default)', action='store_true')\n",
        "    parser.add_argument('-device', '--device', type=int, help=\"Force to run the script on a specified device\", required=False, default=None)\n",
        "    parser.add_argument('-b', '--block_samples', type=int, help=\"Number of samples per block for block momentum (BM) distributed learner (if 0 BM learner is not used)\", required=False, default=None)\n",
        "    parser.add_argument('-a', '--distributed_after', help='Number of samples to train with before running distributed', type=int, required=False, default='0')\n",
        "\n",
        "    args = vars(parser.parse_args())\n",
        "\n",
        "    if args['outputdir'] is not None:\n",
        "        model_path = args['outputdir'] + \"/models\"\n",
        "    if args['logdir'] is not None:\n",
        "        log_dir = args['logdir']\n",
        "    if args['device'] is not None:\n",
        "        # Setting one worker on GPU and one worker on CPU. Otherwise memory consumption is too high for a single GPU.\n",
        "        if Communicator.rank() == 0:\n",
        "            C.device.try_set_default_device(C.device.gpu(args['device']))\n",
        "        else:\n",
        "            C.device.try_set_default_device(C.device.cpu())\n",
        "\n",
        "    data_path = args['datadir']\n",
        "\n",
        "    if not os.path.isdir(data_path):\n",
        "        raise RuntimeError(\"Directory %s does not exist\" % data_path)\n",
        "\n",
        "    train_data = os.path.join(data_path, 'train_map.txt')\n",
        "    test_data = os.path.join(data_path, 'val_map.txt')\n",
        "\n",
        "    alexnet_train_and_eval(train_data, test_data,\n",
        "                           max_epochs=args['num_epochs'],\n",
        "                           restore=not args['restart'],\n",
        "                           log_to_file=args['logdir'],\n",
        "                           num_mbs_per_log=200,\n",
        "                           num_quantization_bits=args['quantized_bits'],\n",
        "                           block_size=args['block_samples'],\n",
        "                           warm_up=args['distributed_after'],\n",
        "                           minibatch_size=args['minibatch_size'],\n",
        "                           epoch_size=args['epoch_size'],\n",
        "                           gen_heartbeat=True)\n",
        "    # Must call MPI finalize when process exit without exceptions\n",
        "    Communicator.finalize()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-473fc9b908e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcntk\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cntk'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}